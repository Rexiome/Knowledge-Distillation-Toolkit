{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import fairseq_mod\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from wav2vec2_inference_pipeline import inference_pipeline\n",
    "from data_loader import LibriSpeechDataLoader\n",
    "from knowledge_distillation.kd_training import KnowledgeDistillationTraining\n",
    "from fairseq_mod.models.wav2vec.teacher_wav2vec2 import TeacherWav2Vec2Model\n",
    "from fairseq_mod.models.wav2vec.student_wav2vec2 import StudentWav2Vec2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configurations and create letter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open('demo_config.yaml','r'), Loader=yaml.FullLoader)\n",
    "target_dict = fairseq_mod.data.Dictionary.load('ltr_dict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "libriSpeech_data_loader = LibriSpeechDataLoader(**config[\"data_loader\"])\n",
    "train_data_loader = libriSpeech_data_loader.get_train_data_loader()\n",
    "val_data_loaders = libriSpeech_data_loader.get_val_data_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference pipeline for validating the student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline_example = inference_pipeline(target_dict, use_cuda=True, input_half=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create student and teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_model.proj_to_decoder.weight is not in student model state_dict\n",
      "student_model.proj_to_decoder.bias is not in student model state_dict\n",
      "Finished loading weights into the student model\n",
      "w2v_encoder.proj.weight is not in teacher model state_dict\n",
      "w2v_encoder.proj.bias is not in teacher model state_dict\n",
      "Finished loading weights into the teacher model\n"
     ]
    }
   ],
   "source": [
    "student_model = StudentWav2Vec2Model.create_student_model(target_dict=target_dict,\n",
    "                                                          fairseq_pretrained_model_path=config[\"knowledge_distillation\"][\"general\"][\"fairseq_pretrained_model_path\"],\n",
    "                                                          **config[\"knowledge_distillation\"][\"student_model\"])\n",
    "teacher_model = TeacherWav2Vec2Model.create_teacher_model(target_dict=target_dict,\n",
    "                                                          fairseq_pretrained_model_path=config[\"knowledge_distillation\"][\"general\"][\"fairseq_pretrained_model_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the projection layer (which outputs probability distributions over tokens) for student and teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_layer(fairseq_pretrained_model_path):\n",
    "    \"\"\"\n",
    "    Get projection layer's weights and biases of wav2vec 2.0 pre-trained model\n",
    "    \"\"\"\n",
    "    w2v = torch.load(fairseq_pretrained_model_path)\n",
    "    return w2v[\"model\"][\"w2v_encoder.proj.weight\"], w2v[\"model\"][\"w2v_encoder.proj.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_layer_weight, proj_layer_bias = get_proj_layer(fairseq_pretrained_model_path=config[\"knowledge_distillation\"][\"general\"][\"fairseq_pretrained_model_path\"])\n",
    "student_model.init_proj_layer_to_decoder(proj_layer_weight, proj_layer_bias)\n",
    "teacher_model.init_proj_layer_to_decoder(proj_layer_weight, proj_layer_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a student model with knowledge distillation and get its performance on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 32\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name          | Type                 | Params\n",
      "-------------------------------------------------------\n",
      "0 | student_model | StudentWav2Vec2Model | 65.5 M\n",
      "1 | teacher_model | TeacherWav2Vec2Model | 317 M \n",
      "-------------------------------------------------------\n",
      "382 M     Trainable params\n",
      "0         Non-trainable params\n",
      "382 M     Total params\n",
      "1,531.611 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d8861610104e6dbe168a3654bbb493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev_clean :0.9922171602126044\n",
      "\n",
      "GPU 0 current active MB: 1567.2637439999999\n",
      "GPU 0 current reserved MB: 1577.058304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514d0c659e61496fb09d26f497802589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d04945e5a34a7b9aef961daa8a2991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev_clean :0.6119969627942293\n",
      "\n",
      "GPU 0 current active MB: 2369.9584\n",
      "GPU 0 current reserved MB: 2642.4115199999997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c6c996988c40009229d5ced76bf1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev_clean :0.5672930903568717\n",
      "\n",
      "GPU 0 current active MB: 2369.9594239999997\n",
      "GPU 0 current reserved MB: 2646.6058239999998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b54d0e88c204fc38fe19f8049935e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev_clean :0.5494495064540622\n",
      "\n",
      "GPU 0 current active MB: 2369.9594239999997\n",
      "GPU 0 current reserved MB: 2648.702976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1206e7d8bd9e4ce5aaa96dfdd36f0aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev_clean :0.5127182991647684\n",
      "\n",
      "GPU 0 current active MB: 2369.9594239999997\n",
      "GPU 0 current reserved MB: 2646.6058239999998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46eba78355ff4218a53a607fe93ddb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dev_clean :0.48395975702353833\n",
      "\n",
      "GPU 0 current active MB: 2369.9594239999997\n",
      "GPU 0 current reserved MB: 2648.702976\n"
     ]
    }
   ],
   "source": [
    "KD_wav2vec2 = KnowledgeDistillationTraining(train_data_loader = train_data_loader,\n",
    "                                            val_data_loaders = val_data_loaders,\n",
    "                                            inference_pipeline = inference_pipeline_example,\n",
    "                                            student_model = student_model,\n",
    "                                            teacher_model = teacher_model,\n",
    "                                            num_gpu_used = config[\"knowledge_distillation\"][\"general\"][\"num_gpu_used\"],\n",
    "                                            temperature = config[\"knowledge_distillation\"][\"general\"][\"temperature\"],\n",
    "                                            final_loss_coeff_dict = config[\"knowledge_distillation\"][\"final_loss_coeff\"],\n",
    "                                            logging_param = ChainMap(config[\"knowledge_distillation\"][\"general\"], config[\"knowledge_distillation\"][\"optimization\"],\n",
    "                                                                     config[\"knowledge_distillation\"][\"final_loss_coeff\"], config[\"knowledge_distillation\"][\"student_model\"],\n",
    "                                                                     config[\"knowledge_distillation\"][\"pytorch_lightning_trainer\"]),\n",
    "                                            **ChainMap(config[\"knowledge_distillation\"][\"optimization\"],\n",
    "                                                       config[\"knowledge_distillation\"][\"pytorch_lightning_trainer\"],\n",
    "                                                       config[\"knowledge_distillation\"][\"comet_info\"])\n",
    "                                            )\n",
    "KD_wav2vec2.start_kd_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = KD_wav2vec2.get_student_model()\n",
    "val_result = inference_pipeline_example.run_inference_pipeline(student_model.cuda(), val_data_loaders[\"dev_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final WER is 48.40\n"
     ]
    }
   ],
   "source": [
    "print(\"final WER is {:.2f}\".format(val_result[\"inference_result\"]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the output above shows, WER has decreased from 99 to 48 after 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
