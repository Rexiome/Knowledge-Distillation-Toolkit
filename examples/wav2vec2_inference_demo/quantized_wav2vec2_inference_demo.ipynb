{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import fairseq_mod\n",
    "\n",
    "from utils import Wav2VecCtc, W2lViterbiDecoder, postprocess_features, post_process_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to quantize a wav2vec 2.0 model. We will use the dev-clean dataset from LibriSpeech which can be downloaded [here](https://www.openslr.org/12). We will quantize the wav2vec 2.0 large model (wav2vec_big_960h) and it can be downloaded [here](https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_big_960h.pt). Without further ado let's get started!\n",
    "\n",
    "\n",
    "### Step 1: Specify paths to wav2vec 2.0 model and dataset. Create the letter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/models/wav2vec2/wav2vec_big_960h.pt\"\n",
    "data_path = \"/home/datasets\"\n",
    "target_dict = fairseq_mod.data.Dictionary.load('ltr_dict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize wav2vec 2.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2VecCtc(\n",
       "  (w2v_encoder): Wav2VecEncoder(\n",
       "    (w2v_model): Wav2Vec2Model(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "      (quantizer): None\n",
       "      (project_q): None\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dequantizer): DeQuantize()\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (final_proj): None\n",
       "    )\n",
       "    (final_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = torch.load(model_path)\n",
    "model = Wav2VecCtc.build_model(w2v[\"args\"], target_dict)\n",
    "model.load_state_dict(w2v[\"model\"], strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define a helper method which calculates the model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    torch.save(model.state_dict(), 'temp_saved_model.pt')\n",
    "    model_size_in_mb = os.path.getsize('temp_saved_model.pt') >> 20\n",
    "    os.remove('temp_saved_model.pt')\n",
    "    return model_size_in_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get the model size of the original wav2vec 2.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model size is 1203.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"original model size is {:.2f} MB\".format(get_model_size(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Quantize the original wav2vec 2.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8, inplace=True)\n",
    "quantized_model.prepare_for_inference_after_quantization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized model size is 338.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"quantized model size is {:.2f} MB\".format(get_model_size(quantized_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the quantized model has a much smaller size!\n",
    "\n",
    "### Step 6: Create decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = W2lViterbiDecoder(target_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_clean_librispeech_data = torchaudio.datasets.LIBRISPEECH(data_path, url='dev-clean', download=False)\n",
    "data_loader = torch.utils.data.DataLoader(dev_clean_librispeech_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Define a helper method which converts one audio sample into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_sample(data_sample, model, decoder, target_dict):\n",
    "    encoder_input = dict()\n",
    "    feature = postprocess_features(data_sample[0][0][0], data_sample[1]).unsqueeze(0)\n",
    "    padding_mask = torch.BoolTensor(feature.size(1)).fill_(False).unsqueeze(0)\n",
    "    \n",
    "    encoder_input[\"source\"] = feature\n",
    "    encoder_input[\"padding_mask\"] = padding_mask\n",
    "    encoder_input[\"features_only\"] = True\n",
    "    encoder_input[\"mask\"] = False\n",
    "    \n",
    "    encoder_out = model(**encoder_input)\n",
    "    emissions = model.get_normalized_probs(encoder_out, log_probs=True)\n",
    "    emissions = emissions.transpose(0, 1).float().cpu().contiguous()\n",
    "    \n",
    "    decoder_out = decoder.decode(emissions)\n",
    "    hyp_pieces = target_dict.string(decoder_out[0][0][\"tokens\"].int().cpu())\n",
    "    prediction = post_process_sentence(hyp_pieces, 'letter')\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Calculate the WER of the quantized model on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2703/2703 [16:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER is 2.75%. Inference took 963 seconds\n"
     ]
    }
   ],
   "source": [
    "predictions, ground_truths, start_time = [], [], time.time()\n",
    "for i, data_sample in enumerate(tqdm(data_loader)):\n",
    "    prediction = process_data_sample(data_sample, quantized_model, decoder, target_dict)\n",
    "    predictions.append(prediction)\n",
    "    ground_truths.append(data_sample[2][0])\n",
    "inference_time = time.time() - start_time\n",
    "wer_score = wer(ground_truths, predictions)\n",
    "print(\"WER is {:.2f}%. Inference took {} seconds\".format(wer_score*100, int(inference_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the quantized model is in CPU, so inference is slow. We used a 48 CPU core machine for this experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
